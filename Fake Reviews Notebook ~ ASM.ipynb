{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font face=\"Times New Roman\" style=\"text-align: center;\">\n",
    "        <h1>Beyond Reviews</h1>\n",
    "        <h2>Validating online consumer reviews using unsupervised machine learning methods.</h2>\n",
    "        <p><strong>Date:</strong> June 15, 2024</p>\n",
    "        <p><strong>Student:</strong> Maurits Christiaan Graaf</p>\n",
    "        <p><strong>Studentnumber:</strong> 660509</p>\n",
    "        <p><strong>Supervisor:</strong> Dr. D.J. (David) Kusterer</p>\n",
    "        <p><strong>Second Reader:</strong> Dr. M. (Maciej) Szymanowski</p>\n",
    "        <p><strong>Department:</strong> Marketing</p>\n",
    "        <p><strong>University:</strong> Rotterdam School of Management</p>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ------ Importing Packages ------ #####\n",
    "#General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import beta\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Import the dataset created and prepared in 'Fake reviews notebook ~ data preparation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149880, 48)\n",
      "Index(['Review_Rating', 'Review_Title', 'Review_Text', 'Review_Images',\n",
      "       'Product_ASIN', 'Parent_Product_ASIN', 'User_ID', 'Review_Timestamp',\n",
      "       'Helpful_Votes', 'Verified_Purchase', 'Main_Category', 'Product_Title',\n",
      "       'Product_Average_Rating', 'Count_product_ratings', 'Product_Features',\n",
      "       'Product_Description', 'Product_Price', 'Product_Images',\n",
      "       'Product_Videos', 'Product_Store', 'Product_Categories',\n",
      "       'Product_Details', 'Products_Bought_Together', 'Product_Subtitle',\n",
      "       'Product_Author', 'overall_category', 'Review_Title_Length',\n",
      "       'Review_Text_Length', 'Rating_Difference', 'Review_Rank',\n",
      "       'Extreme_Rating', 'Average_Text_Length', 'Text_Length_Difference',\n",
      "       'Review_Count', 'Singular_Review', 'Review_Words', 'Review_Word_Count',\n",
      "       'Fully_Capitalized_Words_Count', 'Fully_Capitalized_Words_Proportion',\n",
      "       'Capital_Letters_Excluding_Start_Count',\n",
      "       'Capital_Letters_Excluding_Start_Percentage',\n",
      "       'First_Person_Pronouns_Count', 'First_Person_Pronouns_Ratio',\n",
      "       'Exclamation_Sentence_Ratio', 'Sentiment_Scores', 'Cosine_Similarity',\n",
      "       'Review_Month', 'Review_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read from pickle (pkl)\n",
    "df = pd.read_pickle('concatenated_df.pkl')\n",
    "\n",
    "#Check whether import functioned correctly\n",
    "print(df.shape)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the ASM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Review_Date is in datetime format\n",
    "df['Review_Date'] = pd.to_datetime(df['Review_Timestamp'])\n",
    "\n",
    "# Function to compute the max number of reviews per day\n",
    "def max_number_of_reviews(df):\n",
    "    df['Review_Date'] = pd.to_datetime(df['Review_Timestamp'])\n",
    "    if 'Review_ID' not in df.columns:\n",
    "        df['Review_ID'] = df.index  # Create a unique identifier for review_id\n",
    "    df['Reviews_Per_Day'] = df.groupby(['User_ID', df['Review_Date'].dt.date])['Review_ID'].transform('count')\n",
    "    df['Max_Reviews_Per_Day'] = df.groupby('User_ID')['Reviews_Per_Day'].transform('max')\n",
    "    df['MNR'] = MinMaxScaler().fit_transform(df[['Max_Reviews_Per_Day']])\n",
    "    return df\n",
    "\n",
    "# Function to compute reviewing burstiness\n",
    "def reviewing_burstiness(df, tau=28):\n",
    "    df['First_Review_Date'] = df.groupby('User_ID')['Review_Date'].transform('min')\n",
    "    df['Last_Review_Date'] = df.groupby('User_ID')['Review_Date'].transform('max')\n",
    "    df['Activity_Span'] = (df['Last_Review_Date'] - df['First_Review_Date']).dt.days\n",
    "    df['BST'] = 1 - (df['Activity_Span'] / tau).clip(upper=1)\n",
    "    return df\n",
    "\n",
    "# Function to compute the ratio of first reviews\n",
    "def ratio_of_first_reviews(df):\n",
    "    df['Is_First_Review'] = df.groupby('Product_ASIN')['Review_Timestamp'].rank(method='first') == 1\n",
    "    df['First_Reviews'] = df.groupby('User_ID')['Is_First_Review'].transform('sum')\n",
    "    df['Total_Reviews'] = df.groupby('User_ID')['Review_ID'].transform('count')\n",
    "    df['RFR'] = df['First_Reviews'] / df['Total_Reviews']\n",
    "    return df\n",
    "\n",
    "# Add a column for duplicate/near-duplicate based on cosine similarity\n",
    "df['duplicate'] = (df['Cosine_Similarity'] >= 0.7).astype(int)\n",
    "\n",
    "# Apply the missing feature computations\n",
    "df = max_number_of_reviews(df)\n",
    "df = reviewing_burstiness(df)\n",
    "df = ratio_of_first_reviews(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Review_Rating', 'Review_Title', 'Review_Text', 'Review_Images',\n",
      "       'Product_ASIN', 'Parent_Product_ASIN', 'User_ID', 'Review_Timestamp',\n",
      "       'Helpful_Votes', 'Verified_Purchase', 'Main_Category', 'Product_Title',\n",
      "       'Product_Average_Rating', 'Count_product_ratings', 'Product_Features',\n",
      "       'Product_Description', 'Product_Price', 'Product_Images',\n",
      "       'Product_Videos', 'Product_Store', 'Product_Categories',\n",
      "       'Product_Details', 'Products_Bought_Together', 'Product_Subtitle',\n",
      "       'Product_Author', 'overall_category', 'Review_Title_Length',\n",
      "       'Review_Text_Length', 'Rating_Difference', 'Review_Rank',\n",
      "       'Extreme_Rating', 'Average_Text_Length', 'Text_Length_Difference',\n",
      "       'Review_Count', 'Singular_Review', 'Review_Words', 'Review_Word_Count',\n",
      "       'Fully_Capitalized_Words_Count', 'Fully_Capitalized_Words_Proportion',\n",
      "       'Capital_Letters_Excluding_Start_Count',\n",
      "       'Capital_Letters_Excluding_Start_Percentage',\n",
      "       'First_Person_Pronouns_Count', 'First_Person_Pronouns_Ratio',\n",
      "       'Exclamation_Sentence_Ratio', 'Sentiment_Scores', 'Cosine_Similarity',\n",
      "       'Review_Month', 'Review_ID', 'Review_Date', 'duplicate',\n",
      "       'Reviews_Per_Day', 'Max_Reviews_Per_Day', 'MNR', 'First_Review_Date',\n",
      "       'Last_Review_Date', 'Activity_Span', 'BST', 'Is_First_Review',\n",
      "       'First_Reviews', 'Total_Reviews', 'RFR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Optimized Author Spamicity Model\n",
    "class OptimizedAuthorSpamicityModel:\n",
    "    def __init__(self, n_clusters=2):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.cluster_model = KMeans(n_clusters=self.n_clusters)\n",
    "        self.logistic_model = LogisticRegression()\n",
    "        self.author_spamicity = None\n",
    "        self.review_spamicity = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        # Select relevant features for clustering\n",
    "        features = df[['MNR', 'BST', 'RFR', 'duplicate', \n",
    "                       'Extreme_Rating', 'Rating_Difference', 'Review_Rank', 'Cosine_Similarity']]\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        # Fit clustering model\n",
    "        self.cluster_model.fit(scaled_features)\n",
    "        \n",
    "        # Assign cluster labels to authors\n",
    "        df['Cluster_Label'] = self.cluster_model.labels_\n",
    "        \n",
    "        # Compute spamicity score directly based on cluster characteristics\n",
    "        cluster_spamicity = df.groupby('Cluster_Label')['Cosine_Similarity'].mean().to_dict()\n",
    "        df['Author_Spamicity'] = df['Cluster_Label'].map(cluster_spamicity)\n",
    "        \n",
    "        # Fit a logistic regression model to predict spamicity\n",
    "        df['Spam'] = (df['Cosine_Similarity'] >= 0.7).astype(int)\n",
    "        self.logistic_model.fit(scaled_features, df['Spam'])\n",
    "        df['Review_Spamicity'] = self.logistic_model.predict_proba(scaled_features)[:, 1]\n",
    "        \n",
    "        # Flag reviews with spamicity probability greater than 0.5\n",
    "        df['spam_flag_05'] = df['Review_Spamicity'] > 0.5\n",
    "        \n",
    "        # Store the computed spamicity\n",
    "        self.author_spamicity = df['Author_Spamicity']\n",
    "        self.review_spamicity = df['Review_Spamicity']\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Instantiate the OptimizedAuthorSpamicityModel\n",
    "optimized_asm = OptimizedAuthorSpamicityModel(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maurits\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the dataset\n",
    "result_df = optimized_asm.fit(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write ASM Output To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the CSV\n",
    "# Ensure the Output_Data directory exists\n",
    "output_dir = 'Output_Data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define path\n",
    "output_file_path = os.path.join(output_dir, 'ASM_Output.csv')\n",
    "\n",
    "result_df.to_csv(output_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
